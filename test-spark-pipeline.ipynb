{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b2b36c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, explode,col, when, lit, concat_ws, udf, from_json, struct, to_json,window,sum as agg_sum ,count , aggregate,to_date ,dayofweek,hour , minute ,concat\n",
    "import pandas as pd\n",
    "from pyspark.sql.pandas.functions import pandas_udf\n",
    "from pyspark.sql.functions import collect_list, col, when, lit, concat_ws, udf, from_json, struct, to_json,window,sum as agg_sum ,count , aggregate\n",
    "from pyspark.sql.pandas.functions import pandas_udf, PandasUDFType\n",
    "from abc import ABC, abstractmethod, abstractclassmethod\n",
    "from pyspark.sql import DataFrame, SparkSession\n",
    "from pyspark.sql.functions import col, when, lit, concat_ws, udf, from_json, struct, to_json, window, collect_list ,avg\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType\n",
    "from pipeline.points import TEHRAN_POINTS ,Point\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, FloatType ,ArrayType ,MapType ,IntegerType ,Union\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "13cc9050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------------------+\n",
      "|driverId|      lat|      lng|                time|\n",
      "+--------+---------+---------+--------------------+\n",
      "|     180|35.716124|51.439540|2020-10-20 12:54:...|\n",
      "|     154|35.674238|51.324752|2020-10-20 12:54:...|\n",
      "|     118|35.660226|51.317367|2020-10-20 12:54:...|\n",
      "|     194|35.725052|51.463792|2020-10-20 12:54:...|\n",
      "|     132|35.758336|51.448136|2020-10-20 12:54:...|\n",
      "|     106|35.746166|51.340506|2020-10-20 12:54:...|\n",
      "|     113|35.721141|51.390772|2020-10-20 12:54:...|\n",
      "|     172|35.671891|51.458438|2020-10-20 12:54:...|\n",
      "|     172|35.728834|51.375421|2020-10-20 12:54:...|\n",
      "|     113|35.721141|51.390772|2020-10-20 12:54:...|\n",
      "|     173|35.671891|51.458438|2020-10-20 12:54:...|\n",
      "|     173|35.728834|51.375421|2020-10-20 12:54:...|\n",
      "|     173|35.728834|51.375421|2020-10-20 12:54:...|\n",
      "+--------+---------+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./storage/sample_data2.txt\",header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "769aa293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+---------+--------------------+--------------+\n",
      "|driverId|      lat|      lng|                time|dayOfWeek_Hour|\n",
      "+--------+---------+---------+--------------------+--------------+\n",
      "|     180|35.716124|51.439540|2020-10-20 12:54:...|          3_12|\n",
      "|     154|35.674238|51.324752|2020-10-20 12:54:...|          3_12|\n",
      "|     118|35.660226|51.317367|2020-10-20 12:54:...|          3_12|\n",
      "|     194|35.725052|51.463792|2020-10-20 12:54:...|          3_12|\n",
      "|     132|35.758336|51.448136|2020-10-20 12:54:...|          3_12|\n",
      "|     106|35.746166|51.340506|2020-10-20 12:54:...|          3_12|\n",
      "|     113|35.721141|51.390772|2020-10-20 12:54:...|          3_12|\n",
      "|     172|35.671891|51.458438|2020-10-20 12:54:...|          3_12|\n",
      "|     172|35.728834|51.375421|2020-10-20 12:54:...|          3_12|\n",
      "|     113|35.721141|51.390772|2020-10-20 12:54:...|          3_12|\n",
      "|     173|35.671891|51.458438|2020-10-20 12:54:...|          3_12|\n",
      "|     173|35.728834|51.375421|2020-10-20 12:54:...|          3_12|\n",
      "|     173|35.728834|51.375421|2020-10-20 12:54:...|          3_12|\n",
      "+--------+---------+---------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SELECT DATEPART(WEEKDAY, GETDATE())\n",
    "df =df.withColumn(\"dayOfWeek_Hour\",concat(dayofweek(col(\"time\")),lit(\"_\") ,hour(col(\"time\"))))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "523d234d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0     35.716124\n",
      "1     35.674238\n",
      "2     35.660226\n",
      "3     35.725052\n",
      "4     35.758336\n",
      "5     35.746166\n",
      "6     35.721141\n",
      "7     35.671891\n",
      "8     35.728834\n",
      "9     35.721141\n",
      "10    35.671891\n",
      "11    35.728834\n",
      "12    35.728834\n",
      "Name: _0, dtype: object\n",
      "0     35.716124                                                                 \n",
      "1     35.674238\n",
      "2     35.660226\n",
      "3     35.725052\n",
      "4     35.758336\n",
      "5     35.746166\n",
      "6     35.721141\n",
      "7     35.671891\n",
      "8     35.728834\n",
      "9     35.721141\n",
      "10    35.671891\n",
      "11    35.728834\n",
      "12    35.728834\n",
      "Name: _0, dtype: object\n",
      "[Stage 199:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+--------------------+--------------------+--------------------+--------+----------+----+\n",
      "|driverId|dayOfWeek_Hour|      assigned_point|                   Y|                   u|      p1|        p2|edge|\n",
      "+--------+--------------+--------------------+--------------------+--------------------+--------+----------+----+\n",
      "|     172|          3_12|[POINT_90, POINT_...|[{POINT_90, POINT...|{POINT_90, POINT_...|POINT_90|POINT_5954|   1|\n",
      "|     173|          3_12|[POINT_90, POINT_...|[{POINT_90, POINT...|{POINT_90, POINT_...|POINT_90|POINT_5954|   1|\n",
      "+--------+--------------+--------------------+--------------------+--------------------+--------+----------+----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "@pandas_udf(StringType(), None)\n",
    "def assign_closet_point(lat_series: pd.Series, long_series: pd.Series) -> pd.Series:\n",
    "        df = pd.DataFrame({\"lat\": lat_series, \"long\": long_series})\n",
    "        print(lat_series)\n",
    "        df[\"assigned_point\"] = df.apply(lambda item: min(TEHRAN_POINTS, key=lambda p: Point.distance(p, Point(item[\"lat\"], item[\"long\"], ''))).label, axis=1)\n",
    "        return df[\"assigned_point\"]\n",
    "\n",
    "    \n",
    "@udf(returnType=ArrayType(\n",
    "        StructType([\n",
    "            StructField(\"p1\", StringType()),\n",
    "            StructField(\"p2\", StringType()),\n",
    "            StructField(\"edge\", IntegerType()),\n",
    "        ])))\n",
    "def generate_graph_edges(list_of_point_labels: list):\n",
    "        weights = {label: list_of_point_labels.count(label) for label in set(list_of_point_labels)}\n",
    "        result = []\n",
    "        last_point = list_of_point_labels[0]\n",
    "\n",
    "        for p in list_of_point_labels[1:]:\n",
    "            if p != last_point:\n",
    "                result.append({\"p1\": last_point, \"p2\": p, \"edge\": weights[last_point]})\n",
    "                last_point = p\n",
    "\n",
    "        return result\n",
    "    \n",
    "df = df.withColumn(\"assigned_point\", assign_closet_point(col(\"lat\"), col('lng')))\n",
    "x= df.orderBy(\"time\").groupBy(\"driverId\",\"dayOfWeek_Hour\").agg(collect_list(col(\"assigned_point\")).alias(\"assigned_point\"))\n",
    "x = x.withColumn(\"Y\" ,generate_graph_edges(col(\"assigned_point\")))\n",
    "x= x.withColumn(\"u\", explode(col(\"Y\"))).select(\"*\" ,\"u.*\" )\n",
    "x.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fb5bee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0     35.716124\n",
      "1     35.674238\n",
      "2     35.660226\n",
      "3     35.725052\n",
      "4     35.758336\n",
      "5     35.746166\n",
      "6     35.721141\n",
      "7     35.671891\n",
      "8     35.728834\n",
      "9     35.721141\n",
      "10    35.671891\n",
      "11    35.728834\n",
      "12    35.728834\n",
      "Name: _0, dtype: object\n",
      "0     35.716124                                                                 \n",
      "1     35.674238\n",
      "2     35.660226\n",
      "3     35.725052\n",
      "4     35.758336\n",
      "5     35.746166\n",
      "6     35.721141\n",
      "7     35.671891\n",
      "8     35.728834\n",
      "9     35.721141\n",
      "10    35.671891\n",
      "11    35.728834\n",
      "12    35.728834\n",
      "Name: _0, dtype: object\n",
      "[Stage 217:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+----------+------------------------+\n",
      "|dayOfWeek_Hour|      p1|        p2|avg(edge AS edge_on_avg)|\n",
      "+--------------+--------+----------+------------------------+\n",
      "|          3_12|POINT_90|POINT_5954|                     1.0|\n",
      "+--------------+--------+----------+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "final_df = x.groupBy(\"dayOfWeek_Hour\" ,\"p1\",\"p2\").agg(avg(col(\"edge\").alias(\"edge_on_avg\"))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd273c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8ad7d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91bc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6493e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
